{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "input_file1 = \"QM9_129440_MLtraining\"\n",
    "input_file2 = \"QM9_49762_MLtraining\"\n",
    "targets1 = ['HOMO_eV', 'LUMO_eV', 'c_v']\n",
    "targets2 = ['bps_pred', 'mps_pred', 'fps_pred']\n",
    "# ========= Cấu hình trọng số =========\n",
    "WEIGHTS = {\n",
    "    'RF_score_rank': 0.2,\n",
    "    'XGB_score_rank': 0.2,\n",
    "    'SKB_score_rank': 0.3,\n",
    "    'PCA_score_rank': 0.3,\n",
    "    'FS_BIC_score_rank': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression  \u001b[38;5;66;03m# Thêm import\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression  # Thêm import\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "df2 = pd.read_csv(f'{input_file2}.csv').replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df1 = pd.read_csv(f'{input_file1}.csv').replace([np.inf, -np.inf], np.nan).dropna()\n",
    "epsilon = 1e-6\n",
    "for col in targets1:\n",
    "    if col in df1.columns:\n",
    "        df1.loc[df1[col] == 0, col] = epsilon\n",
    "    if col in df2.columns:\n",
    "        df2.loc[df2[col] == 0, col] = epsilon\n",
    "final_features = {}\n",
    "def calculate_weighted_rank(row):\n",
    "    return sum(row[method] * WEIGHTS[method] for method in WEIGHTS.keys())\n",
    "\n",
    "def calculate_bic_score(model, X, y):\n",
    "    n = len(y)\n",
    "    k = X.shape[1] + 1  # +1 for intercept\n",
    "    y_pred = model.predict(X)\n",
    "    mse = ((y - y_pred) ** 2).mean()\n",
    "    bic = n * np.log(mse) + k * np.log(n)\n",
    "    return bic\n",
    "\n",
    "def forward_selection_with_bic(X, y):\n",
    "    remaining_features = list(X.columns)\n",
    "    selected_features = []\n",
    "    current_bic = None\n",
    "    \n",
    "    while remaining_features:\n",
    "        bic_candidates = []\n",
    "        for feature in remaining_features:\n",
    "            candidate_features = selected_features + [feature]\n",
    "            X_candidate = X[candidate_features]\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_candidate, y)\n",
    "            bic = calculate_bic_score(model, X_candidate, y)\n",
    "            bic_candidates.append((bic, feature))\n",
    "        \n",
    "        bic_candidates.sort()\n",
    "        best_bic, best_feature = bic_candidates[0]\n",
    "        \n",
    "        if current_bic is None or best_bic < current_bic:\n",
    "            selected_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            current_bic = best_bic\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return selected_features\n",
    "\n",
    "def calculate_weighted_rank(row):\n",
    "    return sum(row[method] * WEIGHTS[method] for method in WEIGHTS.keys())\n",
    "open(\"selected_feature.txt\", \"w\", encoding=\"utf-8\").close()\n",
    "open(\"combined.txt\", \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "for target in targets2:\n",
    "    X = df2.drop(columns=['bps_pred', 'mps_pred', 'fps_pred', 'canonical_smiles'])\n",
    "    y = df2[target]\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=7)\n",
    "    rf.fit(X, y)\n",
    "    rf_imp = pd.DataFrame({'feature': X.columns, 'RF_score': rf.feature_importances_})\n",
    "    xgb = XGBRegressor(n_estimators = 1000, random_state=7)\n",
    "    xgb.fit(X, y)\n",
    "    xgb_imp = pd.DataFrame({'feature': X.columns, 'XGB_score': xgb.feature_importances_})\n",
    "    selector = SelectKBest(mutual_info_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    skb_imp = pd.DataFrame({'feature': X.columns, 'SKB_score': selector.scores_})\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=0.9999)\n",
    "    pca.fit(X_scaled)\n",
    "    pca_loadings = pd.DataFrame(pca.components_.T, index=X.columns).abs().sum(axis=1)\n",
    "    pca_imp = pd.DataFrame({'feature': pca_loadings.index, 'PCA_score': pca_loadings.values})\n",
    "    selected_fs_bic = forward_selection_with_bic(X, y)\n",
    "    fs_bic_scores = {feature: 1.0 for feature in selected_fs_bic}\n",
    "    fs_bic_imp = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'FS_BIC_score': [fs_bic_scores.get(f, 0.0) for f in X.columns]  # 1.0 nếu được chọn, 0.0 nếu không\n",
    "    })\n",
    "\n",
    "    combined = rf_imp.merge(skb_imp, on='feature')\\\n",
    "                    .merge(pca_imp, on='feature')\\\n",
    "                    .merge(xgb_imp, on='feature')\\\n",
    "                    .merge(fs_bic_imp, on='feature')\n",
    "\n",
    "\n",
    "    rank_columns = []\n",
    "    for method in ['RF_score', 'SKB_score', 'PCA_score', 'XGB_score', 'FS_BIC_score']:\n",
    "        ascending = False \n",
    "        combined[f'{method}_rank'] = combined[method].rank(ascending=ascending, method='dense')\n",
    "        rank_columns.append(f'{method}_rank')\n",
    "    \n",
    "    combined['Weighted_Avg_Rank'] = combined[rank_columns].apply(\n",
    "        lambda row: sum(row[col] * WEIGHTS.get(col, 0) for col in WEIGHTS.keys()), axis=1\n",
    "    )\n",
    "    with open(\"combined.txt\", \"a\", encoding=\"utf-8\") as file_out:\n",
    "        file_out.write(f\"\\n=== combined dataframe of {target}===\\n\")\n",
    "        file_out.write(combined.to_string())\n",
    "        file_out.write(f\"\\n=== end of combined dataframe ===\\n\")\n",
    "    \n",
    "    top_features = combined.sort_values('Weighted_Avg_Rank').head(20)['feature'].tolist()\n",
    "    final_features[target] = top_features\n",
    "    with open(\"selected_feature.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"\\n{target} : {top_features}\\n\")\n",
    "\n",
    "for target in targets1:\n",
    "    X = df1.drop(columns=['HOMO_eV', 'LUMO_eV', 'c_v', 'canonical_smiles'])\n",
    "    y = df1[target]\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=7)\n",
    "    rf.fit(X, y)\n",
    "    rf_imp = pd.DataFrame({'feature': X.columns, 'RF_score': rf.feature_importances_})\n",
    "    xgb = XGBRegressor(n_estimators=1000, random_state=7)\n",
    "    xgb.fit(X, y)\n",
    "    xgb_imp = pd.DataFrame({'feature': X.columns, 'XGB_score': xgb.feature_importances_})\n",
    "    selector = SelectKBest(mutual_info_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    skb_imp = pd.DataFrame({'feature': X.columns, 'SKB_score': selector.scores_})\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=0.9999)\n",
    "    pca.fit(X_scaled)\n",
    "    pca_loadings = pd.DataFrame(pca.components_.T, index=X.columns).abs().sum(axis=1)\n",
    "    pca_imp = pd.DataFrame({'feature': pca_loadings.index, 'PCA_score': pca_loadings.values})\n",
    "    selected_fs_bic = forward_selection_with_bic(X, y)\n",
    "    fs_bic_scores = {feature: 1.0 for feature in selected_fs_bic}\n",
    "    fs_bic_imp = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'FS_BIC_score': [fs_bic_scores.get(f, 0.0) for f in X.columns]  # 1.0 nếu được chọn, 0.0 nếu không\n",
    "    })\n",
    "\n",
    "    combined = rf_imp.merge(skb_imp, on='feature')\\\n",
    "                    .merge(pca_imp, on='feature')\\\n",
    "                    .merge(xgb_imp, on='feature')\\\n",
    "                    .merge(fs_bic_imp, on='feature')\n",
    "    \n",
    "    combined.fillna(1e-9, inplace=True)  # hoặc 1e-9 nếu cần\n",
    "\n",
    "    rank_columns = []\n",
    "    for method in ['RF_score', 'SKB_score', 'PCA_score', 'XGB_score', 'FS_BIC_score']:\n",
    "        ascending = False\n",
    "        combined[f'{method}_rank'] = combined[method].rank(ascending=ascending, method='dense')\n",
    "        rank_columns.append(f'{method}_rank')\n",
    "    \n",
    "    combined['Weighted_Avg_Rank'] = combined[rank_columns].apply(\n",
    "        lambda row: sum(row[col] * WEIGHTS.get(col, 0) for col in WEIGHTS.keys()), axis=1\n",
    "    )\n",
    "    with open(\"combined.txt\", \"a\", encoding=\"utf-8\") as file_out:\n",
    "        file_out.write(f\"\\n=== combined dataframe of {target}===\\n\")\n",
    "        file_out.write(combined.to_string())\n",
    "        file_out.write(f\"\\n=== end of combined dataframe ===\\n\")\n",
    "\n",
    "    # Chọn top features\n",
    "    top_features = combined.sort_values('Weighted_Avg_Rank').head(30)['feature'].tolist()\n",
    "    final_features[target] = top_features\n",
    "    with open(\"selected_feature.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"\\n{target} : {top_features}\\n\")\n",
    "\n",
    "BPS_features = final_features['bps_pred']\n",
    "MPS_features = final_features['mps_pred']\n",
    "FPS_features = final_features['fps_pred']\n",
    "HOMO_eV_features = final_features['HOMO_eV']\n",
    "LUMO_eV_features = final_features['LUMO_eV']\n",
    "c_v_features = final_features['c_v']\n",
    "\n",
    "def save_model(model_name, model_type, method):\n",
    "    pkl_filename = f'{model_type}_{type(model_name).__name__}_{method}.pkl'\n",
    "    with open(pkl_filename, 'wb') as file:  \n",
    "        pickle.dump(model_name, file)\n",
    "    with open(pkl_filename, 'rb') as file:  \n",
    "        saved_model = pickle.load(file)\n",
    "    print(saved_model)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "target_features2 = {\n",
    "    'bps_pred': BPS_features,\n",
    "    'mps_pred': MPS_features,\n",
    "    'fps_pred': FPS_features\n",
    "}\n",
    "\n",
    "cv = 5\n",
    "\n",
    "for i, target in enumerate(targets2):\n",
    "    print(f\"\\n=== Building models for {target} ===\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    selected_features = target_features2[target]\n",
    "    X = df2[selected_features]\n",
    "    # Handle infinity values by replacing with mean\n",
    "    inf_mask = X.isin([np.inf, -np.inf])\n",
    "    if inf_mask.any().any():\n",
    "        X = X.replace([np.inf, -np.inf], np.nan)\n",
    "        X = X.fillna(X.mean())\n",
    "    y = df2[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "    # 1. Pipeline và param grid cho Random Forest\n",
    "    rf_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', RandomForestRegressor(criterion='absolute_error', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    rf_param_grid = {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [10, 20],\n",
    "    }\n",
    "    \n",
    "    # 2. Pipeline và param grid cho XGBoost\n",
    "    xgb_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', XGBRegressor(objective='reg:absoluteerror', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    xgb_param_grid = {\n",
    "    \"model__n_estimators\": [5000],\n",
    "    \"model__max_depth\": [25],\n",
    "    \"model__learning_rate\": [0.04],\n",
    "    \"model__min_child_weight\": [10]    # Số lượng mẫu tối thiểu ở lá\n",
    "}\n",
    "    \n",
    "    models = [\n",
    "        # ('Random Forest', rf_pipe, rf_param_grid),\n",
    "        ('XGBoost', xgb_pipe, xgb_param_grid)\n",
    "    ]\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    for name, pipe, param_grid in models:\n",
    "        print(f'\\n----- Optimizing {name} for {targets2[i]} -----')\n",
    "        search = GridSearchCV(pipe, param_grid, n_jobs=-1, \n",
    "                            scoring = 'neg_mean_absolute_error' )\n",
    "        search.fit(X_train, y_train,   model__verbose=False       \n",
    ")\n",
    "        \n",
    "        best_model = search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Tính các metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nBest parameters for {name}:\")\n",
    "        for param, value in search.best_params_.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics on Test Set:\")\n",
    "        print(f\"R2 Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"MAPE: {mape:.4f}%\")\n",
    "        \n",
    "        best_models[name] = {\n",
    "            'model': best_model,\n",
    "            'metrics': {\n",
    "                'R2': r2,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'MAPE': mape\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # So sánh kết quả tốt nhất giữa 2 mô hình\n",
    "    print('\\n----- Model Comparison -----')\n",
    "    print(f\"{'Model':<15} {'R2':>8} {'RMSE':>8} {'MAE':>8} {'MAPE':>8}\")\n",
    "    for name, result in best_models.items():\n",
    "        metrics = result['metrics']\n",
    "        print(f\"{name:<15} {metrics['R2']:8.4f} {metrics['RMSE']:8.4f} \" \n",
    "              f\"{metrics['MAE']:8.4f} {metrics['MAPE']:8.4f}%\")\n",
    "    \n",
    "    # Xác định best model dựa trên MAE\n",
    "    best_model_name = min(best_models.items(), \n",
    "                         key=lambda x: x[1]['metrics']['MAE'])[0]\n",
    "    print(f\"\\nBest model for {target} is {best_model_name} \"\n",
    "          f\"(MAE = {best_models[best_model_name]['metrics']['MAE']:.4f})\")\n",
    "    \n",
    "    # Lưu best model\n",
    "    model_name = f\"{targets2[i]}_{best_model_name.replace(' ', '_')}\"\n",
    "    save_model(best_models[best_model_name]['model'], 'regression', targets2[i])\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(f'{target} - Actual vs. Predicted')\n",
    "    plt.text(\n",
    "        min(y_test), \n",
    "        max(y_pred), \n",
    "        f\"MAPE: {mape:.2f}%\\nR²: {r2:.2f}\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "model_paths = {\n",
    "    'bps_model': 'regression_Pipeline_bps_pred.pkl',\n",
    "    'mps_model': 'regression_Pipeline_mps_pred.pkl',\n",
    "}\n",
    "with open(\"selected_feature.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    temp_features = {}\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        key, val = line.split(\":\", 1)\n",
    "        temp_features[key.strip()] = ast.literal_eval(val.strip())\n",
    "\n",
    "BPS_features = temp_features['bps_pred']\n",
    "MPS_features = temp_features['mps_pred']\n",
    "models = {}\n",
    "for name, path in model_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Loading {name} from {path}\")\n",
    "        with open(path, 'rb') as f:\n",
    "            models[name] = pickle.load(f)\n",
    "    else:\n",
    "        print(f\"Warning: {path} does not exist\")\n",
    "X_bps = df1[BPS_features] \n",
    "X_mps = df1[MPS_features]  \n",
    "for name, path in model_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Loading {name} from {path}\")\n",
    "        with open(path, 'rb') as f:\n",
    "            models[name] = pickle.load(f)\n",
    "    else:\n",
    "        print(f\"Warning: {path} does not exist\")\n",
    "\n",
    "# Make predictions if models were loaded successfully\n",
    "if 'bps_model' in models:\n",
    "    # Kiểm tra features tồn tại trong dataframe\n",
    "    missing_features = [feat for feat in BPS_features if feat not in df1.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Warning: Missing features for BPS prediction: {missing_features}\")\n",
    "    else:\n",
    "        X_bps = df1[BPS_features]\n",
    "        df1['bps_predicted'] = models['bps_model'].predict(X_bps)\n",
    "        print(\"BPS predictions added to dataframe\")\n",
    "\n",
    "if 'mps_model' in models:\n",
    "    missing_features = [feat for feat in MPS_features if feat not in df1.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Warning: Missing features for MPS prediction: {missing_features}\")\n",
    "    else:\n",
    "        X_mps = df1[MPS_features]\n",
    "        df1['mps_predicted'] = models['mps_model'].predict(X_mps)\n",
    "        print(\"MPS predictions added to dataframe\")\n",
    "target_features1 = {\n",
    "    'HOMO_eV': HOMO_eV_features + ['bps_predicted', 'mps_predicted'],\n",
    "    'LUMO_eV': LUMO_eV_features + ['bps_predicted', 'mps_predicted'],\n",
    "    'c_v': c_v_features + ['bps_predicted', 'mps_predicted']\n",
    "}\n",
    "\n",
    "for i, target in enumerate(targets1):\n",
    "    print(f\"\\n=== Building models for {target} ===\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    selected_features = target_features1[target]\n",
    "    X = df1[selected_features]\n",
    "    # Handle infinity values by replacing with mean\n",
    "    inf_mask = X.isin([np.inf, -np.inf])\n",
    "    if inf_mask.any().any():\n",
    "        X = X.replace([np.inf, -np.inf], np.nan)\n",
    "        X = X.fillna(X.mean())\n",
    "    y = df1[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "    # 1. Pipeline và param grid cho Random Forest\n",
    "    rf_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', RandomForestRegressor(criterion='absolute_error', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    rf_param_grid = {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [10, 20],\n",
    "    }\n",
    "    \n",
    "    # 2. Pipeline và param grid cho XGBoost\n",
    "    xgb_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', XGBRegressor(objective='reg:absoluteerror', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    xgb_param_grid = {\n",
    "    \"model__n_estimators\": [2000],\n",
    "    \"model__max_depth\": [20],\n",
    "    \"model__learning_rate\": [0.01],\n",
    "    \"model__min_child_weight\": [10]    # Số lượng mẫu tối thiểu ở lá\n",
    "}\n",
    "    \n",
    "    models = [\n",
    "        # ('Random Forest', rf_pipe, rf_param_grid),\n",
    "        ('XGBoost', xgb_pipe, xgb_param_grid)\n",
    "    ]\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    for name, pipe, param_grid in models:\n",
    "        print(f'\\n----- Optimizing {name} for {targets1[i]} -----')\n",
    "        search = GridSearchCV(pipe, param_grid, n_jobs=-1, \n",
    "                            scoring = 'neg_mean_absolute_error' )\n",
    "        search.fit(X_train, y_train,   model__verbose=False       \n",
    ")\n",
    "        \n",
    "        best_model = search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Tính các metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nBest parameters for {name}:\")\n",
    "        for param, value in search.best_params_.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics on Test Set:\")\n",
    "        print(f\"R2 Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"MAPE: {mape:.4f}%\")\n",
    "        \n",
    "        best_models[name] = {\n",
    "            'model': best_model,\n",
    "            'metrics': {\n",
    "                'R2': r2,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'MAPE': mape\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # So sánh kết quả tốt nhất giữa 2 mô hình\n",
    "    print('\\n----- Model Comparison -----')\n",
    "    print(f\"{'Model':<15} {'R2':>8} {'RMSE':>8} {'MAE':>8} {'MAPE':>8}\")\n",
    "    for name, result in best_models.items():\n",
    "        metrics = result['metrics']\n",
    "        print(f\"{name:<15} {metrics['R2']:8.4f} {metrics['RMSE']:8.4f} \" \n",
    "              f\"{metrics['MAE']:8.4f} {metrics['MAPE']:8.4f}%\")\n",
    "    \n",
    "    # Xác định best model dựa trên MAE\n",
    "    best_model_name = min(best_models.items(), \n",
    "                         key=lambda x: x[1]['metrics']['MAE'])[0]\n",
    "    print(f\"\\nBest model for {target} is {best_model_name} \"\n",
    "          f\"(MAE = {best_models[best_model_name]['metrics']['MAE']:.4f})\")\n",
    "    \n",
    "    # Lưu best model\n",
    "    model_name = f\"{targets1[i]}_{best_model_name.replace(' ', '_')}\"\n",
    "    save_model(best_models[best_model_name]['model'], 'regression', targets1[i])\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(f'{target} - Actual vs. Predicted')\n",
    "    plt.text(\n",
    "        min(y_test), \n",
    "        max(y_pred), \n",
    "        f\"MAPE: {mape:.2f}%\\nR²: {r2:.2f}\"\n",
    "    )\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
